{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.bigdatauniversity.com\"><img src = \"https://is4-ssl.mzstatic.com/image/thumb/Purple113/v4/91/42/8b/91428ba5-e783-cce6-767b-e023b2db39dc/AppIcon-0-1x_U007emarketing-0-7-0-85-220.png/246x0w.png\" width = 200, align = \"center\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center><font size=5>Yahoo Finance Web scraping</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of content</h2>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<ul>\n",
    "    <li><a>Web scrapping : one ticker</a>\n",
    "        <ul>\n",
    "            <li><a>Identify_classes and attributs</a></li>\n",
    "            <li><a>Convertion into dataframe</a></li>\n",
    "    </ul>\n",
    "    </li>\n",
    "    <li><a>Web scrapping : Multi tickers</a></li>\n",
    "    <li><a>Web scrapping : Potential Improvements</a></li>\n",
    "\n",
    "Estimated Time Needed: <strong>5 min</strong>\n",
    "</div>\n",
    " \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>What is the purpose of this tool?</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tool is a way to experiment web scrapping on yahoo finance website.The aim is to be able to scrap the approriate attributes upon which an analysis could be made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before hand let's import all the packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import simpledialog\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "from urllib.request import Request, urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Web scrapping : one ticker</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the user will have to input the ticker of the yahoo web page (Tkinter)<p>\n",
    "Knowing that the url is the same for equity instruments , the ticker is the only variable changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = tk.Tk()\n",
    "ROOT.withdraw()\n",
    "# the input dialog\n",
    "ticker = simpledialog.askstring(title=\"Ticker\",\n",
    "                                  prompt=\"Please enter ur ticker\")\n",
    "url = f'https://fr.finance.yahoo.com/quote/{ticker}?p={ticker}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second we’ll use a Python module called BeautifulSoup, the most common web scraping module for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = Request(url)\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "html = soup.prettify('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is messy , we need to figure out how to find the attributes we need in this bulk of non-parsed information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Identify classes and attributes </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, the distinctive mark resides in the class attribute (in our case 'Trsdu(0.3s) Trsdu(0.3s) Fw(b) Fz(36px) Mb(-4px) D(b)).We inspect the HTML lines from the source code of the website , we’ll notice a pattern. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll extract, by turn, each item of interest and store it in a json file:\n",
    "\n",
    "- PRESENT_VALUE.\n",
    "- PRESENT_GROWTH.\n",
    "- PREV_CLOSE.\n",
    "- OPEN.\n",
    "- ASK.\n",
    "- BID.\n",
    "- DAYS_RANGE.\n",
    "- FIFTY_TWO_WK_RANGE.\n",
    "- TD_VOLUME.\n",
    "- AVERAGE_VOLUME_3MONTH\n",
    "- MARKET_CAP\n",
    "- BETA_3Y\n",
    "- PE_RATIO\n",
    "- EPS_RATIO\n",
    "- EARNINGS_DATE\n",
    "- EARNINGS_DATE\n",
    "- DIVIDEND_AND_YIELD\n",
    "- EX_DIVIDEND_DATE\n",
    "- ONE_YEAR_TARGET_PRICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OTHER_DETAILS': {'PRESENT_VALUE': '2\\xa0401,10', 'PREV_CLOSE': '2\\xa0410,39', 'OPEN': '2\\xa0384,33', 'BID': '2\\xa0402,71 x 1000', 'ASK': '2\\xa0404,90 x 1200', 'TD_VOLUME': '3\\xa0092\\xa0643', 'AVERAGE_VOLUME_3MONTH': '6\\xa0027\\xa0435', 'MARKET_CAP': '1,198T', 'PE_RATIO': '114,69', 'EPS_RATIO': '20,94', 'EARNINGS_DATE': ['23 juil. 2020', '27 juil. 2020'], 'DIVIDEND_AND_YIELD': 'S.O. (S.O.)', 'ONE_YEAR_TARGET_PRICE': '2\\xa0645,67'}}\n",
      "----------Extraction of data is complete. Check json file.----------\n"
     ]
    }
   ],
   "source": [
    "company_json = {}\n",
    "other_details = {}\n",
    "for span in soup.findAll('span',\n",
    "                         attrs={'class': 'Trsdu(0.3s) Trsdu(0.3s) Fw(b) Fz(36px) Mb(-4px) D(b)'\n",
    "                         }):\n",
    "    other_details['PRESENT_VALUE'] = span.text.strip()\n",
    "for div in soup.findAll('div', attrs={'class': 'D(ib) Va(t)'}):\n",
    "    for span in div.findAll('span', recursive=False):\n",
    "        other_details['PRESENT_GROWTH'] = span.text.strip()\n",
    "for td in soup.findAll('td', attrs={'data-test': 'PREV_CLOSE-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        other_details['PREV_CLOSE'] = span.text.strip()\n",
    "for td in soup.findAll('td', attrs={'data-test': 'OPEN-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        other_details['OPEN'] = span.text.strip()\n",
    "for td in soup.findAll('td', attrs={'data-test': 'BID-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        other_details['BID'] = span.text.strip()\n",
    "for td in soup.findAll('td', attrs={'data-test': 'ASK-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        other_details['ASK'] = span.text.strip()\n",
    "for td in soup.findAll('td', attrs={'data-test': 'DAYS_RANGE-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        other_details['DAYS_RANGE'] = span.text.strip()\n",
    "for td in soup.findAll('td',\n",
    "                       attrs={'data-test': 'FIFTY_TWO_WK_RANGE-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        other_details['FIFTY_TWO_WK_RANGE'] = span.text.strip()\n",
    "for td in soup.findAll('td', attrs={'data-test': 'TD_VOLUME-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        other_details['TD_VOLUME'] = span.text.strip()\n",
    "for td in soup.findAll('td',\n",
    "                       attrs={'data-test': 'AVERAGE_VOLUME_3MONTH-value'\n",
    "                       }):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        other_details['AVERAGE_VOLUME_3MONTH'] = span.text.strip()\n",
    "for td in soup.findAll('td', attrs={'data-test': 'MARKET_CAP-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        other_details['MARKET_CAP'] = span.text.strip()\n",
    "for td in soup.findAll('td', attrs={'data-test': 'BETA_3Y-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        other_details['BETA_3Y'] = span.text.strip()\n",
    "for td in soup.findAll('td', attrs={'data-test': 'PE_RATIO-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        other_details['PE_RATIO'] = span.text.strip()\n",
    "for td in soup.findAll('td', attrs={'data-test': 'EPS_RATIO-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        other_details['EPS_RATIO'] = span.text.strip()\n",
    "for td in soup.findAll('td', attrs={'data-test': 'EARNINGS_DATE-value'\n",
    "                       }):\n",
    "    other_details['EARNINGS_DATE'] = []\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        other_details['EARNINGS_DATE'].append(span.text.strip())\n",
    "for td in soup.findAll('td',\n",
    "                       attrs={'data-test': 'DIVIDEND_AND_YIELD-value'}):\n",
    "    other_details['DIVIDEND_AND_YIELD'] = td.text.strip()\n",
    "for td in soup.findAll('td',\n",
    "                       attrs={'data-test': 'EX_DIVIDEND_DATE-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        other_details['EX_DIVIDEND_DATE'] = span.text.strip()\n",
    "for td in soup.findAll('td',\n",
    "                       attrs={'data-test': 'ONE_YEAR_TARGET_PRICE-value'\n",
    "                       }):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        other_details['ONE_YEAR_TARGET_PRICE'] = span.text.strip()\n",
    "company_json['OTHER_DETAILS'] = other_details\n",
    "with open('data.json', 'w') as outfile:\n",
    "    json.dump(company_json, outfile, indent=4)\n",
    "print (company_json)\n",
    "with open('output_file.html', 'wb') as file:\n",
    "    file.write(html)\n",
    "print ('----------Extraction of data is complete. Check json file.----------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Convertion into dataframe </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ASK</td>\n",
       "      <td>2 404,90 x 1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AVERAGE_VOLUME_3MONTH</td>\n",
       "      <td>6 027 435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BID</td>\n",
       "      <td>2 402,71 x 1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DIVIDEND_AND_YIELD</td>\n",
       "      <td>S.O. (S.O.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>EARNINGS_DATE</td>\n",
       "      <td>[23 juil. 2020, 27 juil. 2020]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>EPS_RATIO</td>\n",
       "      <td>20,94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MARKET_CAP</td>\n",
       "      <td>1,198T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ONE_YEAR_TARGET_PRICE</td>\n",
       "      <td>2 645,67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OPEN</td>\n",
       "      <td>2 384,33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PE_RATIO</td>\n",
       "      <td>114,69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRESENT_VALUE</td>\n",
       "      <td>2 401,10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PREV_CLOSE</td>\n",
       "      <td>2 410,39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TD_VOLUME</td>\n",
       "      <td>3 092 643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Value\n",
       "ASK                                   2 404,90 x 1200\n",
       "AVERAGE_VOLUME_3MONTH                       6 027 435\n",
       "BID                                   2 402,71 x 1000\n",
       "DIVIDEND_AND_YIELD                        S.O. (S.O.)\n",
       "EARNINGS_DATE          [23 juil. 2020, 27 juil. 2020]\n",
       "EPS_RATIO                                       20,94\n",
       "MARKET_CAP                                     1,198T\n",
       "ONE_YEAR_TARGET_PRICE                        2 645,67\n",
       "OPEN                                         2 384,33\n",
       "PE_RATIO                                       114,69\n",
       "PRESENT_VALUE                                2 401,10\n",
       "PREV_CLOSE                                   2 410,39\n",
       "TD_VOLUME                                   3 092 643"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "data = pd.read_json(\"data.json\") \n",
    "data.rename(columns={\"OTHER_DETAILS\": \"Value\"},inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Web scrapping : Multi tickers</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same reasoning , I've given the chance to the user to fetch multitude of tickers. The user has to input tickers separated by comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AMZN': {'PRESENT_VALUE': '2\\xa0401,10', 'PREV_CLOSE': '2\\xa0410,39', 'OPEN': '2\\xa0384,33', 'BID': '2\\xa0402,71 x 900', 'ASK': '2\\xa0404,90 x 1200', 'TD_VOLUME': '3\\xa0092\\xa0643', 'AVERAGE_VOLUME_3MONTH': '6\\xa0027\\xa0524', 'MARKET_CAP': '1,198T', 'PE_RATIO': '114,69', 'EPS_RATIO': '20,94', 'EARNINGS_DATE': ['23 juil. 2020', '27 juil. 2020'], 'DIVIDEND_AND_YIELD': 'S.O. (S.O.)', 'ONE_YEAR_TARGET_PRICE': '2\\xa0645,67'}}\n",
      "----------Extraction of data is complete. Check json file.----------\n",
      "{'AMZN': {'PRESENT_VALUE': '2\\xa0401,10', 'PREV_CLOSE': '2\\xa0410,39', 'OPEN': '2\\xa0384,33', 'BID': '2\\xa0402,71 x 900', 'ASK': '2\\xa0404,90 x 1200', 'TD_VOLUME': '3\\xa0092\\xa0643', 'AVERAGE_VOLUME_3MONTH': '6\\xa0027\\xa0524', 'MARKET_CAP': '1,198T', 'PE_RATIO': '114,69', 'EPS_RATIO': '20,94', 'EARNINGS_DATE': ['23 juil. 2020', '27 juil. 2020'], 'DIVIDEND_AND_YIELD': 'S.O. (S.O.)', 'ONE_YEAR_TARGET_PRICE': '2\\xa0645,67'}, 'FB': {'PRESENT_VALUE': '225,46', 'PREV_CLOSE': '229,14', 'OPEN': '224,30', 'BID': '226,36 x 1000', 'ASK': '226,50 x 800', 'TD_VOLUME': '28\\xa0900\\xa0544', 'AVERAGE_VOLUME_3MONTH': '27\\xa0101\\xa0270', 'MARKET_CAP': '642,358B', 'PE_RATIO': '30,94', 'EPS_RATIO': '7,29', 'EARNINGS_DATE': ['22 juil. 2020', '27 juil. 2020'], 'DIVIDEND_AND_YIELD': 'S.O. (S.O.)', 'ONE_YEAR_TARGET_PRICE': '237,38'}}\n",
      "----------Extraction of data is complete. Check json file.----------\n",
      "{'AMZN': {'PRESENT_VALUE': '2\\xa0401,10', 'PREV_CLOSE': '2\\xa0410,39', 'OPEN': '2\\xa0384,33', 'BID': '2\\xa0402,71 x 900', 'ASK': '2\\xa0404,90 x 1200', 'TD_VOLUME': '3\\xa0092\\xa0643', 'AVERAGE_VOLUME_3MONTH': '6\\xa0027\\xa0524', 'MARKET_CAP': '1,198T', 'PE_RATIO': '114,69', 'EPS_RATIO': '20,94', 'EARNINGS_DATE': ['23 juil. 2020', '27 juil. 2020'], 'DIVIDEND_AND_YIELD': 'S.O. (S.O.)', 'ONE_YEAR_TARGET_PRICE': '2\\xa0645,67'}, 'FB': {'PRESENT_VALUE': '225,46', 'PREV_CLOSE': '229,14', 'OPEN': '224,30', 'BID': '226,36 x 1000', 'ASK': '226,50 x 800', 'TD_VOLUME': '28\\xa0900\\xa0544', 'AVERAGE_VOLUME_3MONTH': '27\\xa0101\\xa0270', 'MARKET_CAP': '642,358B', 'PE_RATIO': '30,94', 'EPS_RATIO': '7,29', 'EARNINGS_DATE': ['22 juil. 2020', '27 juil. 2020'], 'DIVIDEND_AND_YIELD': 'S.O. (S.O.)', 'ONE_YEAR_TARGET_PRICE': '237,38'}, 'GOOG': {'PRESENT_VALUE': '1\\xa0416,73', 'PREV_CLOSE': '1\\xa0417,84', 'OPEN': '1\\xa0396,86', 'BID': '1\\xa0420,98 x 1200', 'ASK': '1\\xa0426,39 x 800', 'TD_VOLUME': '1\\xa0627\\xa0556', 'AVERAGE_VOLUME_3MONTH': '2\\xa0417\\xa0262', 'MARKET_CAP': '967,933B', 'PE_RATIO': '28,58', 'EPS_RATIO': '49,57', 'EARNINGS_DATE': [], 'DIVIDEND_AND_YIELD': 'S.O. (S.O.)', 'ONE_YEAR_TARGET_PRICE': '1\\xa0527,52'}}\n",
      "----------Extraction of data is complete. Check json file.----------\n"
     ]
    }
   ],
   "source": [
    "ROOT = tk.Tk()\n",
    "ROOT.withdraw()\n",
    "company_json = {}\n",
    "other_details = {}\n",
    "# the input dialog\n",
    "input_string = simpledialog.askstring(title=\"Ticker\",\n",
    "                                  prompt=\"Please enter ur tickers seperated by comma\")\n",
    "ticker  = input_string.split(\",\")\n",
    "for tic in ticker : \n",
    "    url = f'https://fr.finance.yahoo.com/quote/{tic}?p={tic}'\n",
    "    req = Request(url)\n",
    "    webpage = urlopen(req).read()\n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    html = soup.prettify('utf-8')\n",
    "    tick = {}\n",
    "    for span in soup.findAll('span',\n",
    "                         attrs={'class': 'Trsdu(0.3s) Trsdu(0.3s) Fw(b) Fz(36px) Mb(-4px) D(b)'\n",
    "                         }):\n",
    "        tick['PRESENT_VALUE'] = span.text.strip()\n",
    "    for div in soup.findAll('div', attrs={'class': 'D(ib) Va(t)'}):\n",
    "        for span in div.findAll('span', recursive=False):\n",
    "            tick['PRESENT_GROWTH'] = span.text.strip()\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'PREV_CLOSE-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            tick['PREV_CLOSE'] = span.text.strip()\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'OPEN-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            tick['OPEN'] = span.text.strip()\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'BID-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            tick['BID'] = span.text.strip()\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'ASK-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            tick['ASK'] = span.text.strip()\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'DAYS_RANGE-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            tick['DAYS_RANGE'] = span.text.strip()\n",
    "    for td in soup.findAll('td',\n",
    "                       attrs={'data-test': 'FIFTY_TWO_WK_RANGE-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            tick['FIFTY_TWO_WK_RANGE'] = span.text.strip()\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'TD_VOLUME-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            tick['TD_VOLUME'] = span.text.strip()\n",
    "    for td in soup.findAll('td',\n",
    "                       attrs={'data-test': 'AVERAGE_VOLUME_3MONTH-value'\n",
    "                       }):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            tick['AVERAGE_VOLUME_3MONTH'] = span.text.strip()\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'MARKET_CAP-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            tick['MARKET_CAP'] = span.text.strip()\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'BETA_3Y-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            tick['BETA_3Y'] = span.text.strip()\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'PE_RATIO-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            tick['PE_RATIO'] = span.text.strip()\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'EPS_RATIO-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            tick['EPS_RATIO'] = span.text.strip()\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'EARNINGS_DATE-value'\n",
    "                       }):\n",
    "        tick['EARNINGS_DATE'] = []\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            tick['EARNINGS_DATE'].append(span.text.strip())\n",
    "    for td in soup.findAll('td',\n",
    "                       attrs={'data-test': 'DIVIDEND_AND_YIELD-value'}):\n",
    "        tick['DIVIDEND_AND_YIELD'] = td.text.strip()\n",
    "    for td in soup.findAll('td',\n",
    "                       attrs={'data-test': 'EX_DIVIDEND_DATE-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            tick['EX_DIVIDEND_DATE'] = span.text.strip()\n",
    "    for td in soup.findAll('td',\n",
    "                       attrs={'data-test': 'ONE_YEAR_TARGET_PRICE-value'\n",
    "                       }):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            tick['ONE_YEAR_TARGET_PRICE'] = span.text.strip()\n",
    "    company_json[tic] = tick\n",
    "    \n",
    "    with open('data.json', 'w') as outfile:\n",
    "         json.dump(company_json, outfile, indent=4)\n",
    "    print(company_json)\n",
    "    with open('output_file.html', 'wb') as file:\n",
    "        file.write(html)\n",
    "    print ('----------Extraction of data is complete. Check json file.----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMZN</th>\n",
       "      <th>FB</th>\n",
       "      <th>GOOG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>PRESENT_VALUE</td>\n",
       "      <td>2 401,10</td>\n",
       "      <td>225,46</td>\n",
       "      <td>1 416,73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PREV_CLOSE</td>\n",
       "      <td>2 410,39</td>\n",
       "      <td>229,14</td>\n",
       "      <td>1 417,84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OPEN</td>\n",
       "      <td>2 384,33</td>\n",
       "      <td>224,30</td>\n",
       "      <td>1 396,86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BID</td>\n",
       "      <td>2 402,71 x 900</td>\n",
       "      <td>226,36 x 1000</td>\n",
       "      <td>1 420,98 x 1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ASK</td>\n",
       "      <td>2 404,90 x 1200</td>\n",
       "      <td>226,50 x 800</td>\n",
       "      <td>1 426,39 x 800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TD_VOLUME</td>\n",
       "      <td>3 092 643</td>\n",
       "      <td>28 900 544</td>\n",
       "      <td>1 627 556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AVERAGE_VOLUME_3MONTH</td>\n",
       "      <td>6 027 524</td>\n",
       "      <td>27 101 270</td>\n",
       "      <td>2 417 262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MARKET_CAP</td>\n",
       "      <td>1,198T</td>\n",
       "      <td>642,358B</td>\n",
       "      <td>967,933B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PE_RATIO</td>\n",
       "      <td>114,69</td>\n",
       "      <td>30,94</td>\n",
       "      <td>28,58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>EPS_RATIO</td>\n",
       "      <td>20,94</td>\n",
       "      <td>7,29</td>\n",
       "      <td>49,57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>EARNINGS_DATE</td>\n",
       "      <td>[23 juil. 2020, 27 juil. 2020]</td>\n",
       "      <td>[22 juil. 2020, 27 juil. 2020]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DIVIDEND_AND_YIELD</td>\n",
       "      <td>S.O. (S.O.)</td>\n",
       "      <td>S.O. (S.O.)</td>\n",
       "      <td>S.O. (S.O.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ONE_YEAR_TARGET_PRICE</td>\n",
       "      <td>2 645,67</td>\n",
       "      <td>237,38</td>\n",
       "      <td>1 527,52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 AMZN  \\\n",
       "PRESENT_VALUE                                2 401,10   \n",
       "PREV_CLOSE                                   2 410,39   \n",
       "OPEN                                         2 384,33   \n",
       "BID                                    2 402,71 x 900   \n",
       "ASK                                   2 404,90 x 1200   \n",
       "TD_VOLUME                                   3 092 643   \n",
       "AVERAGE_VOLUME_3MONTH                       6 027 524   \n",
       "MARKET_CAP                                     1,198T   \n",
       "PE_RATIO                                       114,69   \n",
       "EPS_RATIO                                       20,94   \n",
       "EARNINGS_DATE          [23 juil. 2020, 27 juil. 2020]   \n",
       "DIVIDEND_AND_YIELD                        S.O. (S.O.)   \n",
       "ONE_YEAR_TARGET_PRICE                        2 645,67   \n",
       "\n",
       "                                                   FB             GOOG  \n",
       "PRESENT_VALUE                                  225,46         1 416,73  \n",
       "PREV_CLOSE                                     229,14         1 417,84  \n",
       "OPEN                                           224,30         1 396,86  \n",
       "BID                                     226,36 x 1000  1 420,98 x 1200  \n",
       "ASK                                      226,50 x 800   1 426,39 x 800  \n",
       "TD_VOLUME                                  28 900 544        1 627 556  \n",
       "AVERAGE_VOLUME_3MONTH                      27 101 270        2 417 262  \n",
       "MARKET_CAP                                   642,358B         967,933B  \n",
       "PE_RATIO                                        30,94            28,58  \n",
       "EPS_RATIO                                        7,29            49,57  \n",
       "EARNINGS_DATE          [22 juil. 2020, 27 juil. 2020]               []  \n",
       "DIVIDEND_AND_YIELD                        S.O. (S.O.)      S.O. (S.O.)  \n",
       "ONE_YEAR_TARGET_PRICE                          237,38         1 527,52  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "multi_data = pd.read_json(\"data.json\") \n",
    "multi_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Web scrapping : Potential Improvements</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many improvement may be brought to this code.The data has to be cleaned to be exploited <p>\n",
    "On of the improvements is to Retrieve historical data giving the user the freedom to fetch on a range of date.\n",
    "Also build a function which take tickers , historical depth and the attributes needed or even Scheduling the Scrape Job"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
